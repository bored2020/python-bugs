import requests
import bs4
#加载爬虫所需要的包
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
#豆瓣设置了网页反爬虫，所以要加这行代码来伪装成浏览器进行爬取，这里要根据具体运行的环境进行浏览器配置。
res= requests.get("https://movie.douban.com/top250",headers={'User-Agent': user_agent})
#设置了浏览器伪装
soup = bs4.BeautifulSoup(res.text,"html.parser")
targets = soup.find_all("div",class_='hd')
for each in targets:
    print(each.a.span.text)
